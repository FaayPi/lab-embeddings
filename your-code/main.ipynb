{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "This lab is designed to help you solidify your understanding of embeddings by applying them to tasks like semantic similarity, clustering, and building a semantic search system.\n",
    "\n",
    "### Tasks:\n",
    "- Task 1: Semantic Similarity Comparison\n",
    "- Task 2: Document Clustering\n",
    "- Task 3: Enhance the Semantic Search System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Semantic Similarity Comparison\n",
    "### Objective:\n",
    "Compare semantic similarity between pairs of sentences using cosine similarity and embeddings.\n",
    "\n",
    "### Steps:\n",
    "1. Load a pre-trained Sentence Transformer model.\n",
    "2. Encode the sentence pairs.\n",
    "3. Compute cosine similarity for each pair.\n",
    "\n",
    "### Dataset:\n",
    "- \"A dog is playing in the park.\" vs. \"A dog is running in a field.\"\n",
    "- \"I love pizza.\" vs. \"I enjoy ice cream.\"\n",
    "- \"What is AI?\" vs. \"How does a computer learn?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between:\n",
      "  'A dog is playing in the park.'\n",
      "  'A dog is running in a field.'\n",
      "  => 0.522\n",
      "\n",
      "Similarity between:\n",
      "  'I love pizza.'\n",
      "  'I enjoy ice cream.'\n",
      "  => 0.528\n",
      "\n",
      "Similarity between:\n",
      "  'What is AI?'\n",
      "  'How does a computer learn?'\n",
      "  => 0.319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sentence pairs\n",
    "sentence_pairs = [\n",
    "    (\"A dog is playing in the park.\", \"A dog is running in a field.\"),\n",
    "    (\"I love pizza.\", \"I enjoy ice cream.\"),\n",
    "    (\"What is AI?\", \"How does a computer learn?\")\n",
    "]\n",
    "# Encoding\n",
    "sentences = [s for pair in sentence_pairs for s in pair]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Compute similarities\n",
    "# Step 3: Compute cosine similarities for each pair\n",
    "for i, (sent1, sent2) in enumerate(sentence_pairs):\n",
    "    emb1 = embeddings[2*i].reshape(1, -1)\n",
    "    emb2 = embeddings[2*i+1].reshape(1, -1)\n",
    "    sim = cosine_similarity(emb1, emb2)[0][0]\n",
    "    print(f\"Similarity between:\\n  '{sent1}'\\n  '{sent2}'\\n  => {sim:.3f}\\n\")\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- Which sentence pairs are the most semantically similar? Why?\n",
    "- Can you think of cases where cosine similarity might fail to capture true semantic meaning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Document Clustering\n",
    "### Objective:\n",
    "Cluster a set of text documents into similar groups based on their embeddings.\n",
    "\n",
    "### Steps:\n",
    "1. Encode the documents using Sentence Transformers.\n",
    "2. Use KMeans clustering to group the documents.\n",
    "3. Analyze the clusters for semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (6, 384)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Documents to cluster\n",
    "documents = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"What is the distance between Earth and Mars?\",\n",
    "    \"How do I change a flat tire on a car?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How do I fix a leaky faucet?\"\n",
    "]\n",
    "\n",
    "# Encode documents\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = model.encode(documents)\n",
    "print(\"Embedding shape:\", embeddings.shape)\n",
    "\n",
    "\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans clustering\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#YOUR CODE HERE\n",
    "kmeans = KMeans(n_clusters=3,random_state=100)\n",
    "kmeans.fit(embeddings)\n",
    "pred = kmeans.predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster assignments (pred):\n",
      "[1 0 1 0 2 0]\n",
      "Cluster assignments (kmeans.labels_):\n",
      "[1 0 1 0 2 0]\n",
      "                        sentence  cluster\n",
      "0  A dog is playing in the park.        1\n",
      "1   A dog is running in a field.        0\n",
      "2                  I love pizza.        1\n",
      "3             I enjoy ice cream.        0\n",
      "4                    What is AI?        2\n",
      "5     How does a computer learn?        0\n"
     ]
    }
   ],
   "source": [
    "# Print cluster assignments\n",
    "\n",
    "#YOUR CODE HERE\n",
    "# Option 1: Direkt aus pred\n",
    "print(\"Cluster assignments (pred):\")\n",
    "print(pred)\n",
    "\n",
    "# Option 2: Aus KMeans-Objekt\n",
    "print(\"Cluster assignments (kmeans.labels_):\")\n",
    "print(kmeans.labels_)\n",
    "\n",
    "# Option 3: Wenn du sie zu den ursprünglichen Daten hinzufügen willst\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"sentence\": sentences,\n",
    "    \"cluster\": pred\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- How many clusters make the most sense? Why?\n",
    "- Examine the documents in each cluster. Are they semantically meaningful? Can you assign a semantic \"theme\" to each cluster?\n",
    "- Try this exercise with a larger dataset of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Semantic Search System\n",
    "### Objective:\n",
    "Create a semantic search engine:\n",
    "A user provides a query and you search the dataset for semantically relevant documents to return. Return the top 5 results.\n",
    "\n",
    "### Dataset:\n",
    "- Use the following set of documents:\n",
    "    - \"What is the capital of France?\"\n",
    "    - \"How do I bake a chocolate cake?\"\n",
    "    - \"What is the distance between Earth and Mars?\"\n",
    "    - \"How do I change a flat tire on a car?\"\n",
    "    - \"What is the best way to learn Python?\"\n",
    "    - \"How do I fix a leaky faucet?\"\n",
    "    - \"What are the best travel destinations in Europe?\"\n",
    "    - \"How do I set up a local server?\"\n",
    "    - \"What is quantum computing?\"\n",
    "    - \"How do I build a mobile app?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (10, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Documents dataset\n",
    "documents = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"What is the distance between Earth and Mars?\",\n",
    "    \"How do I change a flat tire on a car?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How do I fix a leaky faucet?\",\n",
    "    \"What are the best travel destinations in Europe?\",\n",
    "    \"How do I set up a local server?\",\n",
    "    \"What is quantum computing?\",\n",
    "    \"How do I build a mobile app?\"\n",
    "]\n",
    "\n",
    "# Compute document embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "doc_embeddings = model.encode(documents)\n",
    "print(\"Embedding shape:\", doc_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the search function\n",
    "#This function should encode the user query and return the top N documents that most resemble it\n",
    "def semantic_search(query, documents, doc_embeddings, top_n=5):\n",
    "    # YOUR CODE HERE\n",
    "      # 1️⃣ Encode the query\n",
    "    query_embedding = model.encode([query])  # shape: (1, embedding_dim)\n",
    "\n",
    "    # 2️⃣ Compute cosine similarity between query and documents\n",
    "    sims = cosine_similarity(query_embedding, doc_embeddings)[0]  # shape: (num_documents,)\n",
    "\n",
    "    # 3️⃣ Get indices of top N most similar documents\n",
    "    top_indices = np.argsort(sims)[::-1][:top_n]\n",
    "\n",
    "    # 4️⃣ Return top documents with their similarity scores\n",
    "    top_docs = [(documents[i], sims[i]) for i in top_indices]\n",
    "    return top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is quantum computing?', 0.4352477),\n",
       " ('What is the best way to learn Python?', 0.3187827),\n",
       " ('How do I build a mobile app?', 0.110440776),\n",
       " ('How do I set up a local server?', 0.0911265),\n",
       " ('What are the best travel destinations in Europe?', 0.090647765)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the search function\n",
    "query = \"Explain programming languages.\"\n",
    "semantic_search(query, documents, doc_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- What are the top-ranked results for the given queries?\n",
    "- How can you improve the ranking explanation for users?\n",
    "- Try this approach with a larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
